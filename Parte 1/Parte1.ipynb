{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ra4ola/APA-Assigment2/blob/main/Parte%201/Parte1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "hDL8ISWnoLDo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.modules.flatten import Flatten\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from google.colab import drive\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "1uLWeEmeoSBc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mount Drive"
      ],
      "metadata": {
        "id": "wz7uj0CTnJhq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "3k2zP4HVO1ui"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Definição de Variáveis"
      ],
      "metadata": {
        "id": "xJY0boP2oQzl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PATH = '/content/drive/MyDrive/APA/Assigment2/Parte3'"
      ],
      "metadata": {
        "id": "QqsvTWy1OuYG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TRAIN = True"
      ],
      "metadata": {
        "id": "WsfdC5vp5ryX"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_size = 28\n",
        "lr = 0.001\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "torch.manual_seed(42)"
      ],
      "metadata": {
        "id": "sNDE3f4Soej3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modelos\n"
      ],
      "metadata": {
        "id": "c8cBMdp9oyMj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "inO5ABCJXK2E"
      },
      "outputs": [],
      "source": [
        "# @title AE\n",
        "\n",
        "class AE(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(AE, self).__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "\n",
        "            nn.Conv2d(in_channels=1, out_channels=8, kernel_size=3, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(8),\n",
        "            nn.ELU(),\n",
        "\n",
        "            nn.Conv2d(in_channels=8, out_channels=32, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ELU(),\n",
        "\n",
        "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ELU(),\n",
        "\n",
        "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ELU(),\n",
        "\n",
        "            nn.Conv2d(in_channels=128, out_channels=16, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.ELU()\n",
        "        )\n",
        "        self.decoder = nn.Sequential(\n",
        "\n",
        "         nn.ConvTranspose2d(in_channels=16, out_channels=128, kernel_size=3, stride=1, padding=1),\n",
        "         nn.BatchNorm2d(128),\n",
        "         nn.ELU(),\n",
        "\n",
        "         nn.ConvTranspose2d(in_channels=128, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
        "         nn.BatchNorm2d(64),\n",
        "         nn.ELU(),\n",
        "\n",
        "         nn.ConvTranspose2d(in_channels=64, out_channels=32, kernel_size=3, stride=1, padding=1),\n",
        "         nn.BatchNorm2d(32),\n",
        "         nn.ELU(),\n",
        "\n",
        "         nn.ConvTranspose2d(in_channels=32, out_channels=8, kernel_size=3, stride=1, padding=1),\n",
        "         nn.BatchNorm2d(8),\n",
        "         nn.ELU(),\n",
        "\n",
        "         nn.Upsample(scale_factor=2, mode='nearest'),  # Upsample\n",
        "         nn.ConvTranspose2d(in_channels=8, out_channels=1, kernel_size=3, stride=1, padding=1),\n",
        "         nn.BatchNorm2d(1),\n",
        "         nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        print(x.shape)\n",
        "        x = self.decoder(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title VAE\n",
        "\n",
        "class VAE(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(VAE, self).__init__()\n",
        "\n",
        "        # Encoder\n",
        "        self.encoder = AE()\n",
        "\n",
        "        # Latent space parameters\n",
        "        self.fc_mean = nn.Linear(3136, 16)\n",
        "        self.fc_logvar = nn.Linear(3136, 16)\n",
        "\n",
        "        # Decoder\n",
        "        self.decoder_fc = nn.Linear(16,3136)\n",
        "        self.decoder = AE()\n",
        "\n",
        "    def reparameterize(self, mean, logvar):\n",
        "        std = torch.exp(0.5 * logvar)\n",
        "        epsilon = torch.randn_like(std)\n",
        "        return mean + epsilon * std\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Encoder\n",
        "        x = self.encoder.encoder(x)\n",
        "        decoder_size = x.size()\n",
        "        x = x.view(x.size(0), -1)\n",
        "\n",
        "        # Latent space parameters\n",
        "        mean, logvar = self.fc_mean(x), self.fc_logvar(x)\n",
        "\n",
        "        # Reparameterization trick\n",
        "        z = self.reparameterize(mean, logvar)\n",
        "\n",
        "        z = self.decoder_fc(z)\n",
        "        z = z.view(z.size(0),16, 14, 14)\n",
        "\n",
        "        x_recon = self.decoder.decoder(z)\n",
        "\n",
        "        return x_recon, mean, logvar\n",
        "\n"
      ],
      "metadata": {
        "id": "8Dp3ef5zR1Kr"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title DAE\n",
        "\n",
        "class DAE(nn.Module):\n",
        "    def __init__(self):\n",
        "      super(DAE, self).__init__()\n",
        "      self.encoder = AE()\n",
        "\n",
        "    def forward(self, x):\n",
        "      x = self.encoder(x)\n",
        "      return x"
      ],
      "metadata": {
        "id": "lkypzqzhadr5",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Definição de Funções"
      ],
      "metadata": {
        "id": "VprhOk-XYrtJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Funções de Construção das String para os Caminhos"
      ],
      "metadata": {
        "id": "Wv_GokhrYrzI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ModelDirStr(modelName,path = PATH):\n",
        "  return f\"{path}/{modelName}\"\n",
        "def pathModelStr(modelName,epoch, path = PATH):\n",
        "  return f\"{ModelDirStr(modelName,path)}/{modelName}_epoch={epoch}\""
      ],
      "metadata": {
        "id": "mjmgLRa7Wa-2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Função para adicionar Noise"
      ],
      "metadata": {
        "id": "rGwBAp8-ZlJ9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Noise Fuction DAE\n",
        "\n",
        "def add_noise(data, noise_factor=0.5):\n",
        "    noisy_data = data + noise_factor * torch.randn_like(data)\n",
        "    return torch.clamp(noisy_data, 0., 1.)\n"
      ],
      "metadata": {
        "id": "F1FKpOrYZlR2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### Função de Treino\n"
      ],
      "metadata": {
        "id": "zXJB8A6qtlM5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Train Fuction\n",
        "\n",
        "def train(model, criterion, optimizer, train_loader, epochs, modelName, scheduler=None, path=PATH):\n",
        "    os.makedirs(ModelDirStr(modelName=modelName, path=path), exist_ok=True)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()  # Set the model to training mode\n",
        "\n",
        "        epoch_loss = 0\n",
        "\n",
        "        for inputs, _ in train_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            if isinstance(model, VAE):\n",
        "                outputs, mean, log_var = model(inputs)\n",
        "                reconstruction_loss = criterion(outputs, inputs)\n",
        "                kld_loss = -0.5 * torch.sum(1 + log_var - mean.pow(2) - log_var.exp())\n",
        "                loss = reconstruction_loss + kld_loss\n",
        "            else:\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, inputs)\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            epoch_loss = epoch_loss =+ loss.item()\n",
        "\n",
        "        print(f\"Epoch [{epoch + 1}/{epochs}], Loss: {loss.item():.4f}\")\n",
        "\n",
        "        if scheduler is not None:\n",
        "            scheduler.step()\n",
        "\n",
        "        torch.save(model, pathModelStr(modelName=modelName, path=path, epoch=epoch))\n"
      ],
      "metadata": {
        "id": "CXqbiDr6siFo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Função de Implementação das Perdas"
      ],
      "metadata": {
        "id": "pzrClY_WN41-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Evalute Training\n",
        "\n",
        "def evaluate_training(training_loader, loss_fn, num_epochs, modelName, path=PATH):\n",
        "    all_losses = []\n",
        "    all_kl_loss = []\n",
        "\n",
        "    # Load the model outside the epoch loop\n",
        "\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        running_loss = 0.0\n",
        "        running_kld = 0.0\n",
        "        model_path = pathModelStr(modelName=modelName, path=path, epoch=epoch)\n",
        "        model = torch.load(model_path).to(device)\n",
        "\n",
        "        model.eval()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch in training_loader:\n",
        "                inputs, targets = batch\n",
        "                inputs = inputs.to(device)\n",
        "\n",
        "                if isinstance(model, VAE):\n",
        "                    outputs, mean, log_var = model(inputs)\n",
        "                    reconstruction_loss = loss_fn(outputs, inputs)\n",
        "                    kld_loss = -0.5 * torch.sum(1 + log_var - mean.pow(2) - log_var.exp())\n",
        "                    loss = reconstruction_loss + kld_loss\n",
        "                else:\n",
        "                    outputs = model(inputs)\n",
        "                    loss = loss_fn(outputs, inputs)\n",
        "\n",
        "                running_loss += loss.item()\n",
        "                running_kld += kld_loss.item() if isinstance(model, VAE) else 0\n",
        "\n",
        "        all_losses.append(running_loss)\n",
        "        all_kl_loss.append(running_kld)\n",
        "\n",
        "        print(f'Epoch {epoch}: Epoch Loss: {running_loss/len(train_loader):.4f}, KL Divergence: {running_kld:.4f}')\n",
        "\n",
        "    return all_losses, all_kl_loss\n",
        "\n"
      ],
      "metadata": {
        "id": "rmxVpEWzN4Ui"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Função Display Images"
      ],
      "metadata": {
        "id": "hD2vu7sAYr-D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Plot Losses\n",
        "\n",
        "def plot_loss_accuracy(losses, Tittle = 'Traning Loss', curve_Label = 'Loss',X_axis_label = 'Epochs', Y_axis_Label = 'Loss'):\n",
        "    epochs = range(1, len(losses) + 1)\n",
        "\n",
        "    plt.figure(figsize=(12, 4))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(epochs, losses, 'b', label=curve_Label)\n",
        "    plt.title(Tittle)\n",
        "    plt.xlabel(X_axis_label)\n",
        "    plt.ylabel(Y_axis_Label)\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "_BofZJ2FUOqS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Image Reconstruction\n",
        "\n",
        "def reconstruction_images_plot(model,test_loader, Title = 'Reconstruction'):\n",
        "  with torch.no_grad():\n",
        "    for data in test_loader:\n",
        "      inputs, _ = data\n",
        "      inputs = inputs.to(device)\n",
        "\n",
        "      outputs = model(inputs)\n",
        "\n",
        "      n = 10\n",
        "      plt.figure(figsize=(20, 4))\n",
        "      plt.title = Title\n",
        "      for i in range(n):\n",
        "        ax = plt.subplot(2, n, i + 1)\n",
        "        plt.imshow(inputs[i].cpu().view(28, 28).numpy(), cmap='gray')\n",
        "        plt.gray()\n",
        "        ax.get_xaxis().set_visible(False)\n",
        "        ax.get_yaxis().set_visible(False)\n",
        "        ax = plt.subplot(2, n, i + 1 + n)\n",
        "        plt.imshow(outputs[i].cpu().view(28, 28).numpy(), cmap='gray')\n",
        "        plt.gray()\n",
        "        ax.get_xaxis().set_visible(False)\n",
        "        ax.get_yaxis().set_visible(False)\n",
        "\n",
        "      plt.show()\n",
        "      break"
      ],
      "metadata": {
        "id": "Dg874-2PfEOI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importação do DataSet"
      ],
      "metadata": {
        "id": "Fzlrpsivxgln"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title DataSet Import\n",
        "\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
        "train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
        "test_dataset = datasets.MNIST(root='./data', train=False, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=128, shuffle=True)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=128, shuffle=False)"
      ],
      "metadata": {
        "id": "TUP18T9logtY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implementação dos Modelos"
      ],
      "metadata": {
        "id": "kGJQ3159f62N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inicialização do Modelo"
      ],
      "metadata": {
        "id": "WhG2zsKTMdlH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title AE Initialization\n",
        "\n",
        "epochs = 3\n",
        "ae = AE().to(device)\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "optimizerAE = optim.Adam(ae.parameters(), lr = lr)"
      ],
      "metadata": {
        "id": "Pzz82i7uf9xF"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## AE Treino"
      ],
      "metadata": {
        "id": "cKBeijGGNy_A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Treino AE\n",
        "train(\n",
        "      model = ae,\n",
        "      criterion = criterion,\n",
        "      optimizer = optimizerAE,\n",
        "      train_loader = train_loader,\n",
        "      epochs = epochs,\n",
        "      modelName = \"AE\",\n",
        "      scheduler=None,\n",
        "      path = PATH\n",
        "    )"
      ],
      "metadata": {
        "id": "82e4A_RwgmXV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "508cf96d-f56a-44c0-cbcc-fc93a707fcee"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([128, 16, 14, 14])\n",
            "torch.Size([128, 16, 14, 14])\n",
            "torch.Size([128, 16, 14, 14])\n",
            "torch.Size([128, 16, 14, 14])\n",
            "torch.Size([128, 16, 14, 14])\n",
            "torch.Size([128, 16, 14, 14])\n",
            "torch.Size([128, 16, 14, 14])\n",
            "torch.Size([128, 16, 14, 14])\n",
            "torch.Size([128, 16, 14, 14])\n",
            "torch.Size([128, 16, 14, 14])\n",
            "torch.Size([128, 16, 14, 14])\n",
            "torch.Size([128, 16, 14, 14])\n",
            "torch.Size([128, 16, 14, 14])\n",
            "torch.Size([128, 16, 14, 14])\n",
            "torch.Size([128, 16, 14, 14])\n",
            "torch.Size([128, 16, 14, 14])\n",
            "torch.Size([128, 16, 14, 14])\n",
            "torch.Size([128, 16, 14, 14])\n",
            "torch.Size([128, 16, 14, 14])\n",
            "torch.Size([128, 16, 14, 14])\n",
            "torch.Size([128, 16, 14, 14])\n",
            "torch.Size([128, 16, 14, 14])\n",
            "torch.Size([128, 16, 14, 14])\n",
            "torch.Size([128, 16, 14, 14])\n",
            "torch.Size([128, 16, 14, 14])\n",
            "torch.Size([128, 16, 14, 14])\n",
            "torch.Size([128, 16, 14, 14])\n",
            "torch.Size([128, 16, 14, 14])\n",
            "torch.Size([128, 16, 14, 14])\n",
            "torch.Size([128, 16, 14, 14])\n",
            "torch.Size([128, 16, 14, 14])\n",
            "torch.Size([128, 16, 14, 14])\n",
            "torch.Size([128, 16, 14, 14])\n",
            "torch.Size([128, 16, 14, 14])\n",
            "torch.Size([128, 16, 14, 14])\n",
            "torch.Size([128, 16, 14, 14])\n",
            "torch.Size([128, 16, 14, 14])\n",
            "torch.Size([128, 16, 14, 14])\n",
            "torch.Size([128, 16, 14, 14])\n",
            "torch.Size([128, 16, 14, 14])\n",
            "torch.Size([128, 16, 14, 14])\n",
            "torch.Size([128, 16, 14, 14])\n",
            "torch.Size([128, 16, 14, 14])\n",
            "torch.Size([128, 16, 14, 14])\n",
            "torch.Size([128, 16, 14, 14])\n",
            "torch.Size([128, 16, 14, 14])\n",
            "torch.Size([128, 16, 14, 14])\n",
            "torch.Size([128, 16, 14, 14])\n",
            "torch.Size([128, 16, 14, 14])\n",
            "torch.Size([128, 16, 14, 14])\n",
            "torch.Size([128, 16, 14, 14])\n",
            "torch.Size([128, 16, 14, 14])\n",
            "torch.Size([128, 16, 14, 14])\n",
            "torch.Size([128, 16, 14, 14])\n",
            "torch.Size([128, 16, 14, 14])\n",
            "torch.Size([128, 16, 14, 14])\n",
            "torch.Size([128, 16, 14, 14])\n",
            "torch.Size([128, 16, 14, 14])\n",
            "torch.Size([128, 16, 14, 14])\n",
            "torch.Size([128, 16, 14, 14])\n",
            "torch.Size([128, 16, 14, 14])\n",
            "torch.Size([128, 16, 14, 14])\n",
            "torch.Size([128, 16, 14, 14])\n",
            "torch.Size([128, 16, 14, 14])\n",
            "torch.Size([128, 16, 14, 14])\n",
            "torch.Size([128, 16, 14, 14])\n",
            "torch.Size([128, 16, 14, 14])\n",
            "torch.Size([128, 16, 14, 14])\n",
            "torch.Size([128, 16, 14, 14])\n",
            "torch.Size([128, 16, 14, 14])\n",
            "torch.Size([128, 16, 14, 14])\n",
            "torch.Size([128, 16, 14, 14])\n",
            "torch.Size([128, 16, 14, 14])\n",
            "torch.Size([128, 16, 14, 14])\n",
            "torch.Size([128, 16, 14, 14])\n",
            "torch.Size([128, 16, 14, 14])\n",
            "torch.Size([128, 16, 14, 14])\n",
            "torch.Size([128, 16, 14, 14])\n",
            "torch.Size([128, 16, 14, 14])\n",
            "torch.Size([128, 16, 14, 14])\n",
            "torch.Size([128, 16, 14, 14])\n",
            "torch.Size([128, 16, 14, 14])\n",
            "torch.Size([128, 16, 14, 14])\n",
            "torch.Size([128, 16, 14, 14])\n",
            "torch.Size([128, 16, 14, 14])\n",
            "torch.Size([128, 16, 14, 14])\n",
            "torch.Size([128, 16, 14, 14])\n",
            "torch.Size([128, 16, 14, 14])\n",
            "torch.Size([128, 16, 14, 14])\n",
            "torch.Size([128, 16, 14, 14])\n",
            "torch.Size([128, 16, 14, 14])\n",
            "torch.Size([128, 16, 14, 14])\n",
            "torch.Size([128, 16, 14, 14])\n",
            "torch.Size([128, 16, 14, 14])\n",
            "torch.Size([128, 16, 14, 14])\n",
            "torch.Size([128, 16, 14, 14])\n",
            "torch.Size([128, 16, 14, 14])\n",
            "torch.Size([128, 16, 14, 14])\n",
            "torch.Size([128, 16, 14, 14])\n",
            "torch.Size([128, 16, 14, 14])\n",
            "torch.Size([128, 16, 14, 14])\n",
            "torch.Size([128, 16, 14, 14])\n",
            "torch.Size([128, 16, 14, 14])\n",
            "torch.Size([128, 16, 14, 14])\n",
            "torch.Size([128, 16, 14, 14])\n",
            "torch.Size([128, 16, 14, 14])\n",
            "torch.Size([128, 16, 14, 14])\n",
            "torch.Size([128, 16, 14, 14])\n",
            "torch.Size([128, 16, 14, 14])\n",
            "torch.Size([128, 16, 14, 14])\n",
            "torch.Size([128, 16, 14, 14])\n",
            "torch.Size([128, 16, 14, 14])\n",
            "torch.Size([128, 16, 14, 14])\n",
            "torch.Size([128, 16, 14, 14])\n",
            "torch.Size([128, 16, 14, 14])\n",
            "torch.Size([128, 16, 14, 14])\n",
            "torch.Size([128, 16, 14, 14])\n",
            "torch.Size([128, 16, 14, 14])\n",
            "torch.Size([128, 16, 14, 14])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-69-3ebc0d9a4143>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# @title Treino AE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m train(\n\u001b[0m\u001b[1;32m      3\u001b[0m       \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mae\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m       \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m       \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizerAE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-14-52a80384fa28>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, criterion, optimizer, train_loader, epochs, modelName, scheduler, path)\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m             \u001b[0mepoch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepoch_loss\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch [{epoch + 1}/{epochs}], Loss: {loss.item():.4f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title AE Losses Calculation\n",
        "\n",
        "loss,_ =evaluate_training(\n",
        "    training_loader = train_loader,\n",
        "    loss_fn = criterion,\n",
        "    num_epochs = epochs,\n",
        "    modelName = \"AE\",\n",
        "    path = PATH\n",
        "    )\n"
      ],
      "metadata": {
        "id": "eJSEQ1AGlKGl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title AE Plot Losses\n",
        "plot_loss_accuracy(losses = loss, Tittle = 'AE Loss')"
      ],
      "metadata": {
        "id": "yq4j2D5S3erW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DAE Treino"
      ],
      "metadata": {
        "id": "wxUnV0GtNxZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title DAE Initialization\n",
        "\n",
        "dae = DAE().to(device)\n",
        "\n",
        "optimizerDAE = optim.Adam(dae.parameters(), lr = lr)"
      ],
      "metadata": {
        "id": "ZViSAWBoqVD-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Treino DAE\n",
        "\n",
        "train(\n",
        "    model = dae,\n",
        "    criterion = criterion,\n",
        "    optimizer = optimizerDAE,\n",
        "    train_loader = train_loader,\n",
        "    epochs = epochs,\n",
        "    modelName = \"DAE\",\n",
        "    scheduler=None,\n",
        "    path = PATH\n",
        "  )"
      ],
      "metadata": {
        "id": "1vg2UgthM4Xf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title DAE Losses Calculation\n",
        "\n",
        "loss,_ =evaluate_training(\n",
        "    training_loader = train_loader,\n",
        "    loss_fn = criterion,\n",
        "    num_epochs = epochs,\n",
        "    modelName = \"DAE\",\n",
        "    path = PATH\n",
        "  )"
      ],
      "metadata": {
        "id": "Mv_QbRqdNvbW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title DAE Plot Losses\n",
        "plot_loss_accuracy(losses = loss)"
      ],
      "metadata": {
        "id": "OIpkljcINvfT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## VAE Treino"
      ],
      "metadata": {
        "id": "LHf__SzIOIOb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Initialization VAE\n",
        "vae = VAE().to(device)\n",
        "\n",
        "optimizerVAE = optim.Adam(vae.parameters(), lr = lr)"
      ],
      "metadata": {
        "id": "VXJ-w5yYqXZ7"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title VAE Treino\n",
        "train(\n",
        "    model = vae,\n",
        "    criterion = criterion,\n",
        "    optimizer = optimizerVAE,\n",
        "    train_loader = train_loader,\n",
        "    epochs = epochs,\n",
        "    modelName = \"VAE\",\n",
        "    scheduler=None,\n",
        "    path = PATH\n",
        "  )"
      ],
      "metadata": {
        "id": "iz-_r7G9NvjH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67f0fab0-b09a-4654-9ba8-f6a048639d6b"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/3], Loss: 2.0027\n",
            "Epoch [2/3], Loss: 2.3020\n",
            "Epoch [3/3], Loss: 1.6150\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title VAE Calculate Losses\n",
        "\n",
        "loss,kld_loss =evaluate_training(\n",
        "    training_loader = train_loader,\n",
        "    loss_fn = criterion,\n",
        "    num_epochs = epochs,\n",
        "    modelName = \"VAE\",\n",
        "    path = PATH\n",
        "  )"
      ],
      "metadata": {
        "id": "krND6gWpNvny",
        "outputId": "49df006e-b535-429e-f9d0-782ebd5de104",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0: Epoch Loss: 2.0976, KL Divergence: 274.0763\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title VAE Plot Losses\n",
        "\n",
        "plot_loss_accuracy(losses= loss)"
      ],
      "metadata": {
        "id": "NduR2aGuNvrq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Reconstrução das Imagens\n",
        "reconstruction_images_plot(dae,test_loader)"
      ],
      "metadata": {
        "id": "lCJQYUD4oAEW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Latent Space"
      ],
      "metadata": {
        "id": "LJSFEu6qsQoa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Latent Space Calculation  and Plot Fuction\n",
        "def extract_latent_space_and_labels_with_tsne(model, training_loader, device):\n",
        "    latent_space = []\n",
        "    labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, data in enumerate(training_loader):\n",
        "            model.eval()\n",
        "            mu = model.encode(data[0].to(device))\n",
        "            latent_space.append(mu)\n",
        "            labels.append(data[1])\n",
        "\n",
        "    latent_space = torch.cat(latent_space, dim=0).cpu().numpy()\n",
        "    labels = torch.cat(labels, dim=0).cpu().numpy()\n",
        "\n",
        "    # Apply t-SNE\n",
        "    tsne = TSNE(n_components=2, random_state=42)\n",
        "    latent_tsne = tsne.fit_transform(latent_space)\n",
        "\n",
        "    # Plot the t-SNE visualization\n",
        "    plt.scatter(latent_tsne[:, 0], latent_tsne[:, 1], c=labels, cmap='viridis')\n",
        "    plt.colorbar()\n",
        "    plt.title(\"t-SNE Visualization of Latent Space\")\n",
        "    plt.show()\n",
        "\n",
        "    return latent_space, labels, latent_tsne"
      ],
      "metadata": {
        "id": "2ZCdOz6csSXp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latent_spaceae, labelsae, latent_tsneae = extract_latent_space_and_labels_with_tsne(ae, train_loader, device)"
      ],
      "metadata": {
        "id": "sETmXAmIslOB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latent_spacedae, labelsdae, latent_tsnedae = extract_latent_space_and_labels_with_tsne(dae, training_loader, device)"
      ],
      "metadata": {
        "id": "Fe8wDpbOsqb_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latent_spacedvae, labelsvae, latent_tsnevae = extract_latent_space_and_labels_with_tsne(vae, training_loader, device)"
      ],
      "metadata": {
        "id": "ed7nztK4sywB"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "history_visible": true,
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}