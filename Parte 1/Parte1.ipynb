{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ra4ola/APA-Assigment2/blob/main/Parte%201/Parte1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "hDL8ISWnoLDo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.modules.flatten import Flatten\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from google.colab import drive\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "1uLWeEmeoSBc"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "3k2zP4HVO1ui",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6dc2154e-d15d-440d-9abf-9624f2ab6d7a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-3b8a479202a4>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'drive' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Definição de Variáveis"
      ],
      "metadata": {
        "id": "xJY0boP2oQzl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PATH = '/content/drive/MyDrive/APA/Assigment2/Parte3'"
      ],
      "metadata": {
        "id": "QqsvTWy1OuYG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_size = 28\n",
        "lr = 0.001\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "sNDE3f4Soej3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Outras"
      ],
      "metadata": {
        "id": "VprhOk-XYrtJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Funções de Construção das String para os Caminhos"
      ],
      "metadata": {
        "id": "Wv_GokhrYrzI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ModelDirStr(modelName,path = PATH):\n",
        "  return f\"{path}/{modelName}\"\n",
        "def pathModelStr(modelName,epoch, path = PATH):\n",
        "  return f\"{ModelDirStr(modelName,path)}/{modelName}_epoch={epoch}\""
      ],
      "metadata": {
        "id": "mjmgLRa7Wa-2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Função Display Images"
      ],
      "metadata": {
        "id": "hD2vu7sAYr-D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def reconstruction_images_plot(model,test_loader):\n",
        "  with torch.no_grad():\n",
        "    for data in test_loader:\n",
        "      inputs, _ = data\n",
        "      inputs = inputs.to(device)\n",
        "\n",
        "      outputs = model(inputs)\n",
        "\n",
        "      n = 10\n",
        "      plt.figure(figsize=(20, 4))\n",
        "      for i in range(n):\n",
        "        ax = plt.subplot(2, n, i + 1)\n",
        "        plt.imshow(inputs[i].cpu().view(28, 28).numpy(), cmap='gray')\n",
        "        plt.gray()\n",
        "        ax.get_xaxis().set_visible(False)\n",
        "        ax.get_yaxis().set_visible(False)\n",
        "        ax = plt.subplot(2, n, i + 1 + n)\n",
        "        plt.imshow(outputs[i].cpu().view(28, 28).numpy(), cmap='gray')\n",
        "        plt.gray()\n",
        "        ax.get_xaxis().set_visible(False)\n",
        "        ax.get_yaxis().set_visible(False)\n",
        "\n",
        "      plt.show()\n",
        "      break"
      ],
      "metadata": {
        "id": "Dg874-2PfEOI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Função de Implementação das Perdas"
      ],
      "metadata": {
        "id": "pzrClY_WN41-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_training(model,training_loader, loss_fn, num_epochs,modelName, path = PATH):\n",
        "    all_losses = []\n",
        "    all_ssim = []\n",
        "    all_psnr = []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        # Load the model\n",
        "        model_path = pathModelStr(\n",
        "            modelName = modelName,\n",
        "            path = path,\n",
        "            epoch = epoch\n",
        "            )\n",
        "        model = torch.load(model_path)\n",
        "        model.to(device)\n",
        "        model.eval()\n",
        "\n",
        "        running_loss = 0.0\n",
        "        running_psnr = 0.0\n",
        "        runningn_ssim = 0.0\n",
        "        with torch.no_grad():\n",
        "            for batch in training_loader:\n",
        "                inputs, targets = batch\n",
        "                inputs = inputs.to(device)\n",
        "                outputs = model(inputs)\n",
        "                loss = loss_fn(outputs, inputs)\n",
        "\n",
        "                psnr = 10 * torch.log10(1 / loss)\n",
        "                ssim = ssim(outputs, inputs)\n",
        "\n",
        "                running_loss += loss.item()\n",
        "                running_psnr += psnr.item()\n",
        "                runningn_ssim += ssim.item()\n",
        "\n",
        "        running_loss /= len(training_loader)\n",
        "        running_psnr /= len(training_loader)\n",
        "        runningn_ssim /= len(training_loader)\n",
        "\n",
        "\n",
        "        all_losses.append(running_loss)\n",
        "        all_psnr.append(running_psnr)\n",
        "        all_ssim.appende(running_ssim)\n",
        "\n",
        "        print(f'Epoch {epoch}: Validation Loss: {valid_loss:.4f}, Accuracy: {accuracy * 100:.2f}%')\n",
        "\n",
        "    return all_losses, all_psnr,all_ssim\n"
      ],
      "metadata": {
        "id": "rmxVpEWzN4Ui"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_loss_accuracy(losses, accuracies):\n",
        "    epochs = range(1, len(losses) + 1)\n",
        "\n",
        "    plt.figure(figsize=(12, 4))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(epochs, losses, 'b', label='Validation Loss')\n",
        "    plt.title('Validation Loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(epochs, accuracies, 'r', label='Accuracy')\n",
        "    plt.title('Accuracy')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "_BofZJ2FUOqS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def reconstruction_images_plot(model,test_loader):\n",
        "  with torch.no_grad():\n",
        "    for data in test_loader:\n",
        "      inputs, _ = data\n",
        "      inputs = inputs.to(device)\n",
        "\n",
        "      outputs = model(inputs)\n",
        "      # Display original and reconstructed images\n",
        "      n = 10  # Number of digits to display\n",
        "      plt.figure(figsize=(20, 4))\n",
        "      for i in range(n):\n",
        "        ax = plt.subplot(2, n, i + 1)\n",
        "        plt.imshow(inputs[i].cpu().view(28, 28).numpy(), cmap='gray')\n",
        "        plt.gray()\n",
        "        ax.get_xaxis().set_visible(False)\n",
        "        ax.get_yaxis().set_visible(False)\n",
        "        ax = plt.subplot(2, n, i + 1 + n)\n",
        "        plt.imshow(outputs[i].cpu().view(28, 28).numpy(), cmap='gray')\n",
        "        plt.gray()\n",
        "        ax.get_xaxis().set_visible(False)\n",
        "        ax.get_yaxis().set_visible(False)\n",
        "\n",
        "      plt.show()\n",
        "      break\n"
      ],
      "metadata": {
        "id": "zeXLbNNpbcSP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def trainKLDiv(model,criterion,optimizer,train_loader,epochs,modelName,scheduler=None, path = PATH):\n",
        "  os.makedirs(ModelDirStr(modelName= modelName,path= path), exist_ok=True)\n",
        "  for epoch in range(epochs):\n",
        "    for data in train_loader:\n",
        "      inputs, _ = data\n",
        "      inputs = inputs.to(device)\n",
        "      optimizer.zero_grad()\n",
        "      outputs, mean, log_var = model(inputs)\n",
        "\n",
        "      reconstruction_loss = criterion(outputs, inputs)\n",
        "      kld_loss = -0.5 * torch.sum(1 + log_var - mean.pow(2) - log_var.exp())\n",
        "      loss = reconstruction_loss + kld_loss\n",
        "\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "    print(f\"Epoch [{epoch + 1}/{epochs}], Loss: {loss.item():.4f}\")\n",
        "\n",
        "    if scheduler is not None:\n",
        "      scheduler.step()\n",
        "\n",
        "    torch.save(model, pathModelStr(modelName= modelName,path = path, epoch = epoch))"
      ],
      "metadata": {
        "id": "9Z2a1CUDAOgR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "00X5uazAaD3_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## *AE*\n"
      ],
      "metadata": {
        "id": "39Lo2Zd_VmRj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### Função de Treino *AE*\n"
      ],
      "metadata": {
        "id": "zXJB8A6qtlM5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def AEtrain(model,criterion,optimizer,train_loader,epochs,modelName,scheduler=None, path = PATH):\n",
        "  os.makedirs(ModelDirStr(modelName= modelName,path= path), exist_ok=True)\n",
        "  for epoch in range(epochs):\n",
        "    for data in train_loader:\n",
        "        inputs, _ = data\n",
        "        inputs = inputs.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, inputs)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    print(f\"Epoch [{epoch + 1}/{epochs}], Loss: {loss.item():.4f}\")\n",
        "\n",
        "    if scheduler is not None:\n",
        "      scheduler.step()\n",
        "\n",
        "    torch.save(model, pathModelStr(modelName= modelName,path = path, epoch = epoch))"
      ],
      "metadata": {
        "id": "CXqbiDr6siFo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## *VAE*"
      ],
      "metadata": {
        "id": "Yq1vSNpEAPNU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Função de Treino *VAE*\n",
        "\n",
        "#### Kullback-Leibler Divergence (KLD) Loss:\n",
        "\n",
        "$$ D_{KL} = -\\frac{1}{2} \\sum_{i} (1 - \\mu_{i}^{2} + \\log(\\sigma_{i}^{2}) - e^{\\log(\\sigma_{i}^{2})}) $$\n"
      ],
      "metadata": {
        "id": "DU-us8jLbKs_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importação do DataSet"
      ],
      "metadata": {
        "id": "Fzlrpsivxgln"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
        "train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
        "test_dataset = datasets.MNIST(root='./data', train=False, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=128, shuffle=True)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=128, shuffle=False)"
      ],
      "metadata": {
        "id": "TUP18T9logtY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modelos\n"
      ],
      "metadata": {
        "id": "c8cBMdp9oyMj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## *AE*"
      ],
      "metadata": {
        "id": "4rTylxElr__l"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "inO5ABCJXK2E"
      },
      "outputs": [],
      "source": [
        "class AE(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(AE, self).__init__()\n",
        "        self.encoder_conv = nn.Sequential(\n",
        "\n",
        "            nn.Conv2d(in_channels=1, out_channels=8, kernel_size=3, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(8),\n",
        "            nn.ELU(),\n",
        "\n",
        "            nn.Conv2d(in_channels=8, out_channels=32, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ELU(),\n",
        "\n",
        "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ELU(),\n",
        "\n",
        "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ELU(),\n",
        "\n",
        "            nn.Conv2d(in_channels=128, out_channels=16, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.ELU()\n",
        "        )\n",
        "        self.decoder_conv = nn.Sequential(\n",
        "\n",
        "         nn.ConvTranspose2d(in_channels=16, out_channels=128, kernel_size=3, stride=1, padding=1),\n",
        "         nn.BatchNorm2d(128),\n",
        "         nn.ELU(),\n",
        "\n",
        "         nn.ConvTranspose2d(in_channels=128, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
        "         nn.BatchNorm2d(64),\n",
        "         nn.ELU(),\n",
        "\n",
        "         nn.ConvTranspose2d(in_channels=64, out_channels=32, kernel_size=3, stride=1, padding=1),\n",
        "         nn.BatchNorm2d(32),\n",
        "         nn.ELU(),\n",
        "\n",
        "         nn.ConvTranspose2d(in_channels=32, out_channels=8, kernel_size=3, stride=1, padding=1),\n",
        "         nn.BatchNorm2d(8),\n",
        "         nn.ELU(),\n",
        "\n",
        "         nn.Upsample(scale_factor=2, mode='nearest'),  # Upsample\n",
        "         nn.ConvTranspose2d(in_channels=8, out_channels=1, kernel_size=3, stride=1, padding=1),\n",
        "         nn.BatchNorm2d(1),\n",
        "         nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder_conv(x)\n",
        "        x = self.decoder_conv(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## *VAE*\n"
      ],
      "metadata": {
        "id": "XUpPHtDvtZmw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class VAE(nn.Module):\n",
        "    def __init__(self):\n",
        "      super(VAE, self).__init__()\n",
        "      self.encoder_conv = nn.Sequential(\n",
        "          nn.Conv2d(1, 8, 3, 2, 1),\n",
        "          nn.BatchNorm2d(8),\n",
        "          nn.ELU(inplace=True),\n",
        "\n",
        "          nn.Conv2d(8, 32, 3, 1, 1),\n",
        "          nn.BatchNorm2d(32),\n",
        "          nn.ELU(inplace=True),\n",
        "\n",
        "          nn.Conv2d(32, 64, 3, 1, 1),\n",
        "          nn.BatchNorm2d(64),\n",
        "          nn.ELU(inplace=True),\n",
        "\n",
        "          nn.Conv2d(64, 128, 3, 1, 1),\n",
        "          nn.BatchNorm2d(128),\n",
        "          nn.ELU(inplace=True),\n",
        "        )\n",
        "\n",
        "      self.mean_layer = nn.Linear(128 * (image_size // 2) ** 2, 16)\n",
        "\n",
        "      self.logvar_layer = nn.Linear(128 * (image_size // 2) ** 2, 16)\n",
        "\n",
        "      self.decoder_conv = nn.Sequential(\n",
        "\n",
        "          nn.ConvTranspose2d(16, 128, 3, 1, 1),\n",
        "          nn.BatchNorm2d(128),\n",
        "          nn.ELU(inplace=True),\n",
        "\n",
        "          nn.ConvTranspose2d(128, 64, 3, 1, 1),\n",
        "          nn.BatchNorm2d(64),\n",
        "          nn.ELU(inplace=True),\n",
        "\n",
        "          nn.ConvTranspose2d(64, 32, 3, 1, 1),\n",
        "          nn.BatchNorm2d(32),\n",
        "          nn.ELU(inplace=True),\n",
        "\n",
        "          nn.ConvTranspose2d(32, 8, 3, 1, 1),\n",
        "          nn.BatchNorm2d(8),\n",
        "          nn.ELU(inplace=True),\n",
        "\n",
        "          nn.Upsample(scale_factor=2, mode='nearest'),\n",
        "          nn.ConvTranspose2d(8, 1, 3, 1, 1),\n",
        "          nn.BatchNorm2d(1),\n",
        "          nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "      x = add_noise()\n",
        "      x = self.encoder_conv(x)\n",
        "      x = x.view(x.size(0), -1)\n",
        "      mean, logvar = self.mean_layer(x), self.logvar_layer(x)\n",
        "      epsilon = torch.randn_like(torch.exp(0.5 * logvar)).to(device)\n",
        "      x = mean + logvar*epsilon\n",
        "      x = self.decoder_conv(x.view(x.size(0), 16, (image_size // 2), (image_size // 2)))\n",
        "      return x, mean, logvar\n",
        "\n"
      ],
      "metadata": {
        "id": "8Dp3ef5zR1Kr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DAE"
      ],
      "metadata": {
        "id": "gH-zqPffaCEm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Função para adicionar Noise"
      ],
      "metadata": {
        "id": "rGwBAp8-ZlJ9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def add_noise(data, noise_factor=0.5):\n",
        "    noisy_data = data + noise_factor * torch.randn_like(data)\n",
        "    return torch.clamp(noisy_data, 0., 1.)\n"
      ],
      "metadata": {
        "id": "F1FKpOrYZlR2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DAE(nn.Module):\n",
        "    def __init__(self):\n",
        "      super(DAE, self).__init__()\n",
        "      self.encoder_conv = nn.Sequential(\n",
        "          nn.Conv2d(1, 8, 3, 2, 1),\n",
        "          nn.BatchNorm2d(8),\n",
        "          nn.ELU(inplace=True),\n",
        "\n",
        "          nn.Conv2d(8, 32, 3, 1, 1),\n",
        "          nn.BatchNorm2d(32),\n",
        "          nn.ELU(inplace=True),\n",
        "\n",
        "          nn.Conv2d(32, 64, 3, 1, 1),\n",
        "          nn.BatchNorm2d(64),\n",
        "          nn.ELU(inplace=True),\n",
        "\n",
        "          nn.Conv2d(64, 128, 3, 1, 1),\n",
        "          nn.BatchNorm2d(128),\n",
        "          nn.ELU(inplace=True),\n",
        "        )\n",
        "\n",
        "      self.mean_layer = nn.Linear(128 * (image_size // 2) ** 2, 16)\n",
        "\n",
        "      self.logvar_layer = nn.Linear(128 * (image_size // 2) ** 2, 16)\n",
        "\n",
        "      self.decoder_conv = nn.Sequential(\n",
        "\n",
        "          nn.ConvTranspose2d(16, 128, 3, 1, 1),\n",
        "          nn.BatchNorm2d(128),\n",
        "          nn.ELU(inplace=True),\n",
        "\n",
        "          nn.ConvTranspose2d(128, 64, 3, 1, 1),\n",
        "          nn.BatchNorm2d(64),\n",
        "          nn.ELU(inplace=True),\n",
        "\n",
        "          nn.ConvTranspose2d(64, 32, 3, 1, 1),\n",
        "          nn.BatchNorm2d(32),\n",
        "          nn.ELU(inplace=True),\n",
        "\n",
        "          nn.ConvTranspose2d(32, 8, 3, 1, 1),\n",
        "          nn.BatchNorm2d(8),\n",
        "          nn.ELU(inplace=True),\n",
        "\n",
        "          nn.Upsample(scale_factor=2, mode='nearest'),\n",
        "          nn.ConvTranspose2d(8, 1, 3, 1, 1),\n",
        "          nn.BatchNorm2d(1),\n",
        "          nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "      x = add_noise(x)\n",
        "      x = self.encoder_conv(x)\n",
        "      x = self.decoder_conv(x)\n",
        "      return x"
      ],
      "metadata": {
        "id": "lkypzqzhadr5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implementação dos Modelos"
      ],
      "metadata": {
        "id": "kGJQ3159f62N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 3\n",
        "ae = AE().to(device)\n",
        "criterion = nn.MSELoss()\n",
        "optimizerAE = optim.Adam(ae.parameters(), lr = lr)"
      ],
      "metadata": {
        "id": "Pzz82i7uf9xF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "AEtrain(\n",
        "    model = ae,\n",
        "    criterion = criterion,\n",
        "    optimizer = optimizerAE,\n",
        "    train_loader = train_loader,\n",
        "    epochs = epochs,\n",
        "    modelName = \"AE\",\n",
        "    scheduler=None,\n",
        "    path = PATH\n",
        "    )"
      ],
      "metadata": {
        "id": "82e4A_RwgmXV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss,acc,x =evaluate_training(\n",
        "    model = ae,\n",
        "    training_loader = train_loader,\n",
        "    loss_fn = criterion,\n",
        "    num_epochs = epochs,\n",
        "    modelName = \"AE\",\n",
        "    path = PATH\n",
        "    )\n"
      ],
      "metadata": {
        "id": "eJSEQ1AGlKGl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_loss_accuracy(losses = loss,accuracies=acc)"
      ],
      "metadata": {
        "id": "yq4j2D5S3erW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    for data in test_loader:\n",
        "        inputs, _ = data\n",
        "        inputs = inputs.to(device)\n",
        "\n",
        "        outputs = ae(inputs)\n",
        "\n",
        "        # Display original and reconstructed images\n",
        "        n = 10  # Number of digits to display\n",
        "        plt.figure(figsize=(20, 4))\n",
        "        for i in range(n):\n",
        "            # Original Images\n",
        "            ax = plt.subplot(2, n, i + 1)\n",
        "            plt.imshow(inputs[i].cpu().view(28, 28).numpy(), cmap='gray')\n",
        "            plt.gray()\n",
        "            ax.get_xaxis().set_visible(False)\n",
        "            ax.get_yaxis().set_visible(False)\n",
        "\n",
        "            # Reconstructed Images\n",
        "            ax = plt.subplot(2, n, i + 1 + n)\n",
        "            plt.imshow(outputs[i].cpu().view(28, 28).numpy(), cmap='gray')\n",
        "            plt.gray()\n",
        "            ax.get_xaxis().set_visible(False)\n",
        "            ax.get_yaxis().set_visible(False)\n",
        "\n",
        "        plt.show()\n",
        "        break  # Only display one batch of test data\n"
      ],
      "metadata": {
        "id": "lCJQYUD4oAEW"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "history_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}