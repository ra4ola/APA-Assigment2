{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ra4ola/APA-Assigment2/blob/main/Parte1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "hDL8ISWnoLDo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.modules.flatten import Flatten\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n"
      ],
      "metadata": {
        "id": "1uLWeEmeoSBc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "3k2zP4HVO1ui",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a153fc81-a761-4702-c0c1-3e7a48683bca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-d5df0069828e>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    130\u001b[0m   )\n\u001b[1;32m    131\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    133\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Defenição de Variáveis"
      ],
      "metadata": {
        "id": "xJY0boP2oQzl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PATH = '/content/drive/MyDrive/APA/Assigment2/Parte3'"
      ],
      "metadata": {
        "id": "QqsvTWy1OuYG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_size = 28\n",
        "lr = 0.001\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "sNDE3f4Soej3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29034d65-519c-45c5-e404-430d36c9cd09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-71bae02285f4>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mimage_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.001\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Definição de Funções"
      ],
      "metadata": {
        "id": "r4tXqe7lthIu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Outras"
      ],
      "metadata": {
        "id": "vjyFl2jzWavM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ModelDirStr(modelName,path = PATH):\n",
        "  return f\"{path}/{modelName}\"\n",
        "def pathModelStr(modelName,epoch, path = PATH):\n",
        "  return f\"{ModelDirStr(modelName,path)}/{modelName}_epoch={epoch}\""
      ],
      "metadata": {
        "id": "mjmgLRa7Wa-2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## *AE*\n"
      ],
      "metadata": {
        "id": "39Lo2Zd_VmRj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### Função de Treino *AE*\n"
      ],
      "metadata": {
        "id": "zXJB8A6qtlM5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def AEtrain(model,criterion,optimizer,train_loader,epochs,modelName,scheduler=None, path = PATH):\n",
        "  os.makedirs(ModelDirStr(modelName= modelName,path= path), exist_ok=True)\n",
        "  for epoch in range(epochs):\n",
        "    for data in train_loader:\n",
        "        inputs, _ = data\n",
        "        inputs = inputs.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, inputs)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    print(f\"Epoch [{epoch + 1}/{epochs}], Loss: {loss.item():.4f}\")\n",
        "\n",
        "    if scheduler is not None:\n",
        "      scheduler.step()\n",
        "\n",
        "    torch.save(model, pathModelStr(modelName= modelName,path = path, epoch = epoch))"
      ],
      "metadata": {
        "id": "CXqbiDr6siFo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## *VAE*"
      ],
      "metadata": {
        "id": "Yq1vSNpEAPNU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Função para adicionar Noise"
      ],
      "metadata": {
        "id": "rGwBAp8-ZlJ9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def add_noise(data, noise_factor=0.5):\n",
        "    noisy_data = data + noise_factor * torch.randn_like(data)\n",
        "    return torch.clamp(noisy_data, 0., 1.)\n"
      ],
      "metadata": {
        "id": "F1FKpOrYZlR2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Função de Treino *VAE*\n",
        "\n",
        "#### Kullback-Leibler Divergence (KLD) Loss:\n",
        "\n",
        "$$ D_{KL} = -\\frac{1}{2} \\sum_{i} (1 - \\mu_{i}^{2} + \\log(\\sigma_{i}^{2}) - e^{\\log(\\sigma_{i}^{2})}) $$\n"
      ],
      "metadata": {
        "id": "DU-us8jLbKs_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def VAEtrain(model,criterion,optimizer,train_loader,epochs,modelName,scheduler=None, path = PATH):\n",
        "  os.makedirs(ModelDirStr(modelName= modelName,path= path), exist_ok=True)\n",
        "  for epoch in range(epochs):\n",
        "    for data in train_loader:\n",
        "      inputs, _ = data\n",
        "      inputs = inputs.to(device)\n",
        "      optimizer.zero_grad()\n",
        "      outputs, mean, log_var = model(add_noise(inputs))\n",
        "\n",
        "      reconstruction_loss = criterion(outputs, inputs)\n",
        "      kld_loss = -0.5 * torch.sum(1 + log_var - mean.pow(2) - log_var.exp())\n",
        "      loss = reconstruction_loss + kld_loss\n",
        "\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "    print(f\"Epoch [{epoch + 1}/{epochs}], Loss: {loss.item():.4f}\")\n",
        "\n",
        "    if scheduler is not None:\n",
        "      scheduler.step()\n",
        "\n",
        "    torch.save(model, pathModelStr(modelName= modelName,path = path, epoch = epoch))"
      ],
      "metadata": {
        "id": "9Z2a1CUDAOgR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Função de Implementação das Perdas\n"
      ],
      "metadata": {
        "id": "pzrClY_WN41-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_training(training_loader, loss_fn, num_epochs,modelName, path = PATH):\n",
        "    all_losses = []\n",
        "    all_accuracies = []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        # Load the model\n",
        "        model_path = pathModelStr(modelName = modelName, path = path)\n",
        "        model = torch.load(model_path)\n",
        "        model.to(device)\n",
        "        model.eval()\n",
        "\n",
        "        # Evaluate the model\n",
        "        valid_loss = 0.0\n",
        "        num_correct = 0\n",
        "        num_examples = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch in training_loader:\n",
        "                inputs, targets = batch\n",
        "                inputs = inputs.to(device)\n",
        "                targets = targets.to(device)\n",
        "                output = model(inputs)\n",
        "                loss = loss_fn(output, targets)\n",
        "                valid_loss += loss.item()\n",
        "\n",
        "                preds = torch.argmax(output, dim=1)\n",
        "                correct = preds.eq(targets)\n",
        "                num_correct += correct.sum().item()\n",
        "                num_examples += correct.shape[0]\n",
        "\n",
        "        valid_loss /= len(training_loader)\n",
        "\n",
        "        accuracy = num_correct / num_examples\n",
        "        all_losses.append(valid_loss)\n",
        "        all_accuracies.append(accuracy)\n",
        "\n",
        "        print(f'Epoch {epoch}: Validation Loss: {valid_loss:.4f}, Accuracy: {accuracy * 100:.2f}%')\n",
        "\n",
        "    return all_losses, all_accuracies\n"
      ],
      "metadata": {
        "id": "rmxVpEWzN4Ui"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_loss_accuracy(losses, accuracies):\n",
        "    epochs = range(1, len(losses) + 1)\n",
        "\n",
        "    plt.figure(figsize=(12, 4))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(epochs, losses, 'b', label='Validation Loss')\n",
        "    plt.title('Validation Loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(epochs, accuracies, 'r', label='Accuracy')\n",
        "    plt.title('Accuracy')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "_BofZJ2FUOqS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def reconstruction_images_plot(model,test_loader):\n",
        "  with torch.no_grad():\n",
        "    for data in test_loader:\n",
        "      inputs, _ = data\n",
        "      inputs = inputs.to(device)\n",
        "\n",
        "      outputs = model(inputs)\n",
        "      # Display original and reconstructed images\n",
        "      n = 10  # Number of digits to display\n",
        "      plt.figure(figsize=(20, 4))\n",
        "      for i in range(n):\n",
        "        ax = plt.subplot(2, n, i + 1)\n",
        "        plt.imshow(inputs[i].cpu().view(28, 28).numpy(), cmap='gray')\n",
        "        plt.gray()\n",
        "        ax.get_xaxis().set_visible(False)\n",
        "        ax.get_yaxis().set_visible(False)\n",
        "        ax = plt.subplot(2, n, i + 1 + n)\n",
        "        plt.imshow(outputs[i].cpu().view(28, 28).numpy(), cmap='gray')\n",
        "        plt.gray()\n",
        "        ax.get_xaxis().set_visible(False)\n",
        "        ax.get_yaxis().set_visible(False)\n",
        "\n",
        "      plt.show()\n",
        "      break\n"
      ],
      "metadata": {
        "id": "zeXLbNNpbcSP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importação do DataSet"
      ],
      "metadata": {
        "id": "Fzlrpsivxgln"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
        "train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
        "test_dataset = datasets.MNIST(root='./data', train=False, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=128, shuffle=True)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=128, shuffle=False)"
      ],
      "metadata": {
        "id": "TUP18T9logtY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6dcd1e0-dfad-4510-a10b-97dcac8e8bfe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 153846223.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 123987404.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 54992775.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 12863287.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modelos\n"
      ],
      "metadata": {
        "id": "c8cBMdp9oyMj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Auto-Encoder Convolution Layer"
      ],
      "metadata": {
        "id": "4rTylxElr__l"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "inO5ABCJXK2E"
      },
      "outputs": [],
      "source": [
        "class AEconv(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Autoencoder, self).__init__()\n",
        "        self.encoder_conv = nn.Sequential(\n",
        "\n",
        "            nn.Conv2d(in_channels=1, out_channels=8, kernel_size=3, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(8),\n",
        "            nn.ELU(),\n",
        "\n",
        "            nn.Conv2d(in_channels=8, out_channels=32, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ELU(),\n",
        "\n",
        "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ELU(),\n",
        "\n",
        "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ELU(),\n",
        "\n",
        "            nn.Conv2d(in_channels=128, out_channels=16, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.ELU()\n",
        "        )\n",
        "        self.decoder_conv = nn.Sequential(\n",
        "\n",
        "         nn.ConvTranspose2d(in_channels=16, out_channels=128, kernel_size=3, stride=1, padding=1),\n",
        "         nn.BatchNorm2d(128),\n",
        "         nn.ELU(),\n",
        "\n",
        "         nn.ConvTranspose2d(in_channels=128, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
        "         nn.BatchNorm2d(64),\n",
        "         nn.ELU(),\n",
        "\n",
        "         nn.ConvTranspose2d(in_channels=64, out_channels=32, kernel_size=3, stride=1, padding=1),\n",
        "         nn.BatchNorm2d(32),\n",
        "         nn.ELU(),\n",
        "\n",
        "         nn.ConvTranspose2d(in_channels=32, out_channels=8, kernel_size=3, stride=1, padding=1),\n",
        "         nn.BatchNorm2d(8),\n",
        "         nn.ELU(),\n",
        "\n",
        "         nn.Upsample(scale_factor=2, mode='nearest'),  # Upsample\n",
        "         nn.ConvTranspose2d(in_channels=8, out_channels=1, kernel_size=3, stride=1, padding=1),\n",
        "         nn.BatchNorm2d(1),\n",
        "         nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder_conv(x)\n",
        "        x = self.decoder_conv(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## VAE Encoder Convolution\n"
      ],
      "metadata": {
        "id": "XUpPHtDvtZmw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class nnModel(nn.Module):\n",
        "    def __init__(self):\n",
        "      super(nnModel, self).__init__()\n",
        "      self.encoder_conv = nn.Sequential(\n",
        "          nn.Conv2d(1, 8, 3, 2, 1),\n",
        "          nn.BatchNorm2d(8),\n",
        "          nn.ELU(inplace=True),\n",
        "\n",
        "          nn.Conv2d(8, 32, 3, 1, 1),\n",
        "          nn.BatchNorm2d(32),\n",
        "          nn.ELU(inplace=True),\n",
        "\n",
        "          nn.Conv2d(32, 64, 3, 1, 1),\n",
        "          nn.BatchNorm2d(64),\n",
        "          nn.ELU(inplace=True),\n",
        "\n",
        "          nn.Conv2d(64, 128, 3, 1, 1),\n",
        "          nn.BatchNorm2d(128),\n",
        "          nn.ELU(inplace=True),\n",
        "        )\n",
        "\n",
        "      self.mean_layer = nn.Linear(128 * (image_size // 2) ** 2, 16)\n",
        "\n",
        "      self.logvar_layer = nn.Linear(128 * (image_size // 2) ** 2, 16)\n",
        "\n",
        "      self.decoder_conv = nn.Sequential(\n",
        "\n",
        "          nn.ConvTranspose2d(16, 128, 3, 1, 1),\n",
        "          nn.BatchNorm2d(128),\n",
        "          nn.ELU(inplace=True),\n",
        "\n",
        "          nn.ConvTranspose2d(128, 64, 3, 1, 1),\n",
        "          nn.BatchNorm2d(64),\n",
        "          nn.ELU(inplace=True),\n",
        "\n",
        "          nn.ConvTranspose2d(64, 32, 3, 1, 1),\n",
        "          nn.BatchNorm2d(32),\n",
        "          nn.ELU(inplace=True),\n",
        "\n",
        "          nn.ConvTranspose2d(32, 8, 3, 1, 1),\n",
        "          nn.BatchNorm2d(8),\n",
        "          nn.ELU(inplace=True),\n",
        "\n",
        "          nn.Upsample(scale_factor=2, mode='nearest'),\n",
        "          nn.ConvTranspose2d(8, 1, 3, 1, 1),\n",
        "          nn.BatchNorm2d(1),\n",
        "          nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "      x = self.encoder_conv(x)\n",
        "      x = x.view(x.size(0), -1)  # Flatten before linear layers\n",
        "      mean, logvar = self.mean_layer(x), self.logvar_layer(x)\n",
        "      epsilon = torch.randn_like(torch.exp(0.5 * logvar)).to(device)\n",
        "      x = mean + logvar*epsilon\n",
        "      x = self.decoder_conv(x.view(x.size(0), 16, (image_size // 2), (image_size // 2)))  # Reshape before decoding\n",
        "      return x, mean, logvar\n",
        "\n"
      ],
      "metadata": {
        "id": "8Dp3ef5zR1Kr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "with torch.no_grad():\n",
        "    for data in test_loader:\n",
        "        inputs, _ = data\n",
        "        inputs = inputs.to(device)\n",
        "\n",
        "        outputs = autoencoder(inputs)\n",
        "\n",
        "\n",
        "        # Display original and reconstructed images\n",
        "        n = 10  # Number of digits to display\n",
        "        plt.figure(figsize=(20, 4))\n",
        "        for i in range(n):\n",
        "            # Original Images\n",
        "            ax = plt.subplot(2, n, i + 1)\n",
        "            plt.imshow(inputs[i].cpu().view(28, 28).numpy(), cmap='gray')\n",
        "            plt.gray()\n",
        "            ax.get_xaxis().set_visible(False)\n",
        "            ax.get_yaxis().set_visible(False)\n",
        "\n",
        "            # Reconstructed Images\n",
        "            ax = plt.subplot(2, n, i + 1 + n)\n",
        "            plt.imshow(outputs[i].cpu().view(28, 28).numpy(), cmap='gray')\n",
        "            plt.gray()\n",
        "            ax.get_xaxis().set_visible(False)\n",
        "            ax.get_yaxis().set_visible(False)\n",
        "\n",
        "        plt.show()\n",
        "        break\n"
      ],
      "metadata": {
        "id": "Dg874-2PfEOI"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}